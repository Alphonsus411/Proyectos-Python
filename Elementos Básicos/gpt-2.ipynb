{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt2_client import GPT2Client\n",
    "\n",
    "gpt2 = GPT2Client('117M') # This could also be `345M`, `774M`, or `1558M`. Rename `save_dir` to anything.\n",
    "gpt2.load_model(force_download=False) # Use cached versions if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt2_client import GPT2Client\n",
    "\n",
    "gpt2 = GPT2Client('117M') # This could also be `345M`, `774M`, or `1558M`\n",
    "\n",
    "gpt2.generate(interactive=True) # Asks user for prompt\n",
    "gpt2.generate(n_samples=4) # Generates 4 pieces of text\n",
    "text = gpt2.generate(return_text=True) # Generates text and returns it in an array\n",
    "gpt2.generate(interactive=True, n_samples=3) # A different prompt each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt2_client import GPT2Client\n",
    "\n",
    "gpt2 = GPT2Client('117M') # This could also be `345M`, `774M`, or `1558M`\n",
    "\n",
    "prompts = [\n",
    "  \"This is a prompt 1\",\n",
    "  \"This is a prompt 2\",\n",
    "  \"This is a prompt 3\",\n",
    "  \"This is a prompt 4\"\n",
    "]\n",
    "\n",
    "text = gpt2.generate_batch_from_prompts(prompts) # returns an array of generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt2_client import GPT2Client\n",
    "\n",
    "gpt2 = GPT2Client('117M') # This could also be `345M`, `774M`, or `1558M`\n",
    "\n",
    "my_corpus = './data/shakespeare.txt' # path to corpus\n",
    "custom_text = gpt2.finetune(my_corpus, return_text=True) # Load your custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt2_client import GPT2Client\n",
    "\n",
    "gpt2 = GPT2Client('117M') # This could also be `345M`, `774M`, or `1558M`\n",
    "gpt2.load_model()\n",
    "\n",
    "# encoding a sentence\n",
    "encs = gpt2.encode_seq(\"Hello world, this is a sentence\")\n",
    "# [15496, 995, 11, 428, 318, 257, 6827]\n",
    "\n",
    "# decoding an encoded sequence\n",
    "decs = gpt2.decode_seq(encs)\n",
    "# Hello world, this is a sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
